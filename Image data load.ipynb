{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e4629e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import All Necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import glob\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae97558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create data loader for images\n",
    "from glob import glob\n",
    "data_im = np.sort( np.array(glob('C:/Users/anikr/Computer Vison/Class 6 -Code/Assignment 1/Image/*'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905d39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create function for extract image and corresponding labels from dataset\n",
    "\n",
    "def all_data_dir(data):\n",
    "    \n",
    "    img = list()\n",
    "    labels = list()\n",
    "\n",
    "    for j in range(len(data)//1):\n",
    "    #vdr = datat[j]\n",
    "        im = np.sort( np.array(glob( data[j]+'/*')))  \n",
    "        random.shuffle(im)\n",
    " \n",
    "        \n",
    "        for i in range(len(im)//1):\n",
    " \n",
    "            img.append(im[i]) \n",
    "            labels.append(j) \n",
    "\n",
    "                \n",
    "    return np.array(img),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25acdd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##generate image data and labels\n",
    "image,label=all_data_dir(data_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150968b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "###determine class number\n",
    "n_cls = np.max(label)+1\n",
    "print(n_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498482a2",
   "metadata": {},
   "source": [
    "# Generate image into pixels array and binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "166dd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function for determine image batch size , height , width & labels\n",
    "\n",
    "def image_data_loader(data_path, labels, batch_size, n_class, shuffle=True, toption=True):\n",
    "    num_samples = len(data_path)\n",
    "    pairs = list(zip(data_path, labels))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(pairs)\n",
    "\n",
    "    for offset in range(0, num_samples, batch_size):\n",
    "        image_batch = np.array(pairs[offset:offset+batch_size])[:, 0]\n",
    "        label_batch = np.array(pairs[offset:offset+batch_size])[:, 1]\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "        for (image_path, label) in zip(image_batch, label_batch):\n",
    "            if str(label.dtype) == '<U9':\n",
    "                label = label\n",
    "            else:\n",
    "                label = to_categorical(label, n_class)\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255\n",
    "            image = tf.image.resize(image, [128, 128])\n",
    "\n",
    "            X_train.append(image)\n",
    "            y_train.append(label)\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "096d1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data=image_data_loader(image, label, 10 , n_cls, shuffle=True, toption=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bccc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(img_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bbac253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 128, 3) (10, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94a5f292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.02500575 0.3100818  0.30339476]\n",
      "  [0.01136092 0.3087496  0.29597026]\n",
      "  [0.02583463 0.29560095 0.283099  ]\n",
      "  ...\n",
      "  [0.02292672 0.2628011  0.26282316]\n",
      "  [0.1558187  0.38836718 0.3629842 ]\n",
      "  [0.04032341 0.23917213 0.2650441 ]]\n",
      "\n",
      " [[0.07057483 0.3055851  0.29660478]\n",
      "  [0.07021533 0.2821775  0.3046607 ]\n",
      "  [0.04418371 0.28927436 0.32425946]\n",
      "  ...\n",
      "  [0.05468391 0.31002057 0.28831932]\n",
      "  [0.03199367 0.2916212  0.31603742]\n",
      "  [0.01203685 0.2629713  0.28263324]]\n",
      "\n",
      " [[0.05959545 0.29506072 0.32282212]\n",
      "  [0.09058264 0.3459494  0.32902497]\n",
      "  [0.03096996 0.32002074 0.29525793]\n",
      "  ...\n",
      "  [0.02149586 0.26761812 0.2529304 ]\n",
      "  [0.04295343 0.26051602 0.26837757]\n",
      "  [0.03905053 0.28361243 0.2606005 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.9078982  1.         0.9797294 ]\n",
      "  [0.95053923 0.9910281  0.9895764 ]\n",
      "  [0.979284   0.9994938  0.9804235 ]\n",
      "  ...\n",
      "  [0.7126628  0.6586333  0.60986096]\n",
      "  [0.6782318  0.65345675 0.581015  ]\n",
      "  [0.6515051  0.6250539  0.5759603 ]]\n",
      "\n",
      " [[0.9989854  0.99585223 0.99925035]\n",
      "  [0.99298406 0.9897841  0.99424475]\n",
      "  [0.9393138  1.         0.9810841 ]\n",
      "  ...\n",
      "  [0.7066653  0.6831871  0.64437973]\n",
      "  [0.70358336 0.683836   0.6231788 ]\n",
      "  [0.69915843 0.6670956  0.6072574 ]]\n",
      "\n",
      " [[0.97951806 0.99757963 0.99617034]\n",
      "  [0.9476912  0.99379236 0.99427444]\n",
      "  [0.98991627 0.99430484 1.        ]\n",
      "  ...\n",
      "  [0.72841156 0.699691   0.6178503 ]\n",
      "  [0.73285294 0.6964732  0.65056944]\n",
      "  [0.71601516 0.7109411  0.6288014 ]]] [0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9a17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
